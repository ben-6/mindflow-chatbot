{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c5a5991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /home/zengjian/venv/lib/python3.8/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/zengjian/venv/lib/python3.8/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/zengjian/venv/lib/python3.8/site-packages (from openai==0.28) (4.66.2)\n",
      "Requirement already satisfied: aiohttp in /home/zengjian/venv/lib/python3.8/site-packages (from openai==0.28) (3.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zengjian/venv/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zengjian/venv/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zengjian/venv/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zengjian/venv/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (2020.12.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/zengjian/venv/lib/python3.8/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zengjian/venv/lib/python3.8/site-packages (from aiohttp->openai==0.28) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zengjian/venv/lib/python3.8/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zengjian/venv/lib/python3.8/site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/zengjian/venv/lib/python3.8/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/zengjian/venv/lib/python3.8/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224324fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb import Client, Settings\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "import string\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "from markupsafe import Markup\n",
    "\n",
    "\n",
    "import ssl\n",
    "import openai\n",
    "\n",
    "import logging\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e6bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a new database\n",
    "# 1: add new client variable with unique var name\n",
    "# 2: update getCollection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e857bf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62236d67bcdb4f0ead30cd18d8104aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='100%'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0654573f60504726a6fef2a8db2519fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='100%'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding = embedding_functions.OpenAIEmbeddingFunction( # Using openai \n",
    "                api_key=os.environ.get('OPENAI_API_KEY'),\n",
    "                model_name=\"text-embedding-ada-002\"\n",
    "            )\n",
    "\n",
    "bellevue_client = Client(Settings(chroma_db_impl=\"duckdb+parquet\", persist_directory=os.environ.get(\"CHATBOT_PATH\")+'/Data/city_bellevue_db'))\n",
    "bellevue_collection = bellevue_client.get_collection('city_bellevue_db', embedding_function=embedding)\n",
    "\n",
    "clyde_hill_client = Client(Settings(chroma_db_impl=\"duckdb+parquet\", persist_directory=os.environ.get(\"CHATBOT_PATH\")+'/Data/clyde_hill_db'))\n",
    "clyde_hill_collection = clyde_hill_client.get_collection('clyde_hill_db', embedding_function=embedding)\n",
    "\n",
    "bsd_client = Client(Settings(chroma_db_impl=\"duckdb+parquet\", persist_directory=os.environ.get(\"CHATBOT_PATH\")+'/Data/bsd_db'))\n",
    "bsd_collection = bsd_client.get_collection('bsd_db', embedding_function=embedding)\n",
    "\n",
    "# Add more databases here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a3411dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCollection(curOrg):\n",
    "    if curOrg == \"City of Bellevue\":\n",
    "        return bellevue_collection\n",
    "    if curOrg == \"City of Clyde Hill\":\n",
    "        return clyde_hill_collection\n",
    "    if curOrg == \"Bellevue School District\":\n",
    "        return bsd_collection\n",
    "    \n",
    "    # Add more databases here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ded1401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Logging\n",
    "logging.basicConfig(filename='chatbot.log', level=logging.INFO, format='%(asctime)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65047309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gptMessage(query, processingHistory, qaHistory, curOrg, websiteTitleSuffix):\n",
    "    collection = getCollection(curOrg)\n",
    "    \n",
    "    # Clarify the prompt using a GPT message\n",
    "    processingHistory.append({\"role\": \"user\", \"content\": query})\n",
    "    promptProcessing = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages=processingHistory)\n",
    "    \n",
    "    preprocessed_query = promptProcessing[\"choices\"][0][\"message\"][\"content\"]\n",
    "    processingHistory.append({\"role\": \"assistant\", \"content\": preprocessed_query})\n",
    "\n",
    "    # ChromaDB Vector Search\n",
    "    docs = collection.query(query_texts=[preprocessed_query], n_results=5, include=[\"documents\", \"metadatas\", \"distances\"])\n",
    "    \n",
    "    # Website titles commonly end with a suffix that can be removed.\n",
    "    for i in range(len(docs['metadatas'][0])):\n",
    "        docs['metadatas'][0][i]['title'] = docs['metadatas'][0][i]['title'].replace(websiteTitleSuffix, \"\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Some documents, especially PDFs, were given a placeholder title when scraping if a title could not be found.\n",
    "    # This code attempts to generate a replacement title using the content of the document, denoted with an asterisk (*)\n",
    "    for i in range(len(docs['documents'][0])):\n",
    "        if curOrg.lower() in docs['metadatas'][0][i]['title'].lower():\n",
    "            clean_text = docs['documents'][0][i].replace(\"\\n\", \" \").replace(\"  \", \" \")\n",
    "            words = word_tokenize(clean_text)\n",
    "            \n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            filtered_words = [word for word in words if word.lower() not in stop_words and word not in set([\",\", \".\", \"'\", \"\\\"\", \":\", \";\", \"â€™\"])]\n",
    "            \n",
    "            freq_dist = FreqDist(filtered_words)\n",
    "            most_common_words = freq_dist.most_common(3)\n",
    "\n",
    "            summary_words = [word for word, _ in most_common_words]\n",
    "\n",
    "            summary_sentence = TreebankWordDetokenizer().detokenize(summary_words)\n",
    "\n",
    "            docs['metadatas'][0][i]['title'] = \"*\" + summary_sentence\n",
    "       \n",
    "    # Start to construct a GPT query using the documents\n",
    "    \n",
    "    formatted_docs = \"\\n\\n\".join(docs['documents'][0])\n",
    "    \n",
    "    \n",
    "    message = preprocessed_query + \". \\nText:\\n\" + formatted_docs\n",
    "    \n",
    "    qaHistory.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages=qaHistory)\n",
    "    reply = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    qaHistory.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    \n",
    "    logging.info(f\"User Prompt: {query}\")\n",
    "    logging.info(f\"Formatted Prompt: {preprocessed_query}\")\n",
    "    logging.info(f\"Response: {reply}\")\n",
    "    \n",
    "    sources = [dict(t) for t in {tuple(d.items()) for d in docs['metadatas'][0]}]\n",
    "    return reply, sources, processingHistory, qaHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f05ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n",
      "Bellevue High School is located at 10416 SE Wolverine Way, Bellevue, WA 98004.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "CORS(app)\n",
    "@app.route('/chroma', methods=['POST'])\n",
    "def endpoint():\n",
    "    data = request.get_json()\n",
    "    message = data.get('message')\n",
    "    \n",
    "    messageHistory = []\n",
    "    if 'messageHistory' in data:\n",
    "        messageHistory = data.get('messageHistory')\n",
    "\n",
    "    qaHistory = []\n",
    "    if 'qaHistory' in data:\n",
    "        qaHistory = data.get('qaHistory')\n",
    "    \n",
    "    curOrg = \"City of Bellevue\"\n",
    "    if 'curOrg' in data:\n",
    "        curOrg = data.get('curOrg')\n",
    "    websiteTitleSuffix = \"| City Of Bellevue\"\n",
    "    if 'websiteTitleSuffix' in data:\n",
    "        websiteTitleSuffix = data.get('websiteTitleSuffix')\n",
    "    \n",
    "    # Process the message and generate a response\n",
    "    res, sources, messageHistory, qaHistory = gptMessage(message, messageHistory, qaHistory, curOrg, websiteTitleSuffix)\n",
    "\n",
    "    while len(str(messageHistory)) > 3500:\n",
    "        messageHistory.pop(1)\n",
    "        messageHistory.pop(1)\n",
    "        \n",
    "    while len(str(qaHistory)) > 3500:\n",
    "        qaHistory.pop(1)\n",
    "        qaHistory.pop(1)\n",
    "                      \n",
    "    print(res)\n",
    "                      \n",
    "    return jsonify({'response': res, 'sources': sources, 'messageHistory': messageHistory, 'qaHistory': qaHistory})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d69249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
